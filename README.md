# Monocular Depth Navigation

[![ROS2](https://img.shields.io/badge/ROS2-Humble-blue)](https://docs.ros.org/en/humble/)
[![Gazebo](https://img.shields.io/badge/Gazebo-Classic-orange)](http://gazebosim.org/)

**Autonomous robot navigation using only a monocular RGB camera** â€” no LiDAR, no depth sensor, no AI and no map.

This project demonstrates that a robot can navigate complex environments using computer vision techniques applied to a single camera feed. The robot detects obstacles by analyzing ground-to-wall transitions in the camera image and uses Nav2 for path planning and obstacle avoidance.

---

## ğŸ¯ Project Goal

Build a fully autonomous navigation system that relies solely on:
- **1 RGB camera** (640Ã—480 @ 30Hz)
- **Visual odometry** (RTAB-Map with ORB features â€” required for real robot, optional in simulation)
- **Ground edge detection** (custom perception algorithm)
- **Nav2** (global + local planning)

No expensive sensors required!

---

## ğŸ—ï¸ System Architecture

At a glance:
- Camera â†’ ground-edge detection â†’ `/ground_edge_scan` â†’ Nav2 costmaps â†’ planner/controller â†’ `/cmd_vel`
- Nav2 plugins used: `RegulatedPurePursuitController` (local controller) + `SmacPlannerHybrid` (global planner)
- Nav2 config: [ros2_ws/src/my_robot/config/nav2_local_params.yaml](ros2_ws/src/my_robot/config/nav2_local_params.yaml)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         GAZEBO SIMULATION                           â”‚
â”‚   Robot with Camera (640Ã—480) + IMU + Differential Drive            â”‚
â”‚   (Provides ground-truth odometry via diff_drive plugin)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼                   â–¼                   â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  RTAB-Map SLAM  â”‚  â”‚ Ground Edge Nodeâ”‚  â”‚ Map Creation Tools  â”‚
   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
   â”‚ â€¢ ORB features  â”‚  â”‚ â€¢ Edge detectionâ”‚  â”‚ â€¢ generate_maze.py  â”‚
   â”‚ â€¢ Visual odom   â”‚  â”‚ â€¢ Depth from    â”‚  â”‚ â€¢ create_map.py     â”‚
   â”‚ â€¢ Loop closure  â”‚  â”‚   geometry      â”‚  â”‚ â†’ Occupancy grid    â”‚
   â”‚ â†’ /odom, /tf    â”‚  â”‚ â†’ /ground_edge_ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚                 â”‚  â”‚   scan          â”‚
   â”‚ (Real robot     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚  only - not     â”‚            â”‚
   â”‚  needed in sim) â”‚            â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
              â”‚                   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚         NAV2            â”‚
          â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
          â”‚  â€¢ Global planner       â”‚
          â”‚  â€¢ Local costmap        â”‚
          â”‚  â€¢ Regulated Pure       â”‚
          â”‚     Pursuit controller  â”‚
          â”‚  â†’ /cmd_vel             â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
                 Robot Motion
```

### Simulation vs Real Robot

| Component | Gazebo Simulation | Real Robot |
|-----------|-------------------|------------|
| Odometry | Gazebo diff_drive plugin (ground truth) | **RTAB-Map required** |
| RTAB-Map | Optional (can use for mapping) | **Required for visual odometry** |
| Perception | Ground Edge Detection | Ground Edge Detection |
| Navigation | Nav2 | Nav2 |

---

## ğŸ”¬ How Ground Edge Detection Works

Traditional monocular depth estimation requires robot motion (optical flow triangulation) and suffers from drift during rotation. This project uses a simpler, more robust approach:

### The Algorithm

1. **Focus on ground region** â€” Analyze bottom 42% of camera image
2. **Scan each column** â€” From bottom to top, detect intensity changes
3. **Find obstacle edge** â€” Where ground meets wall/obstacle
4. **Calculate depth** â€” Using camera geometry:
   ```
   depth = camera_height / tan(pixel_angle)
   ```
5. **Publish LaserScan** â€” Convert to `/ground_edge_scan` for Nav2

### Advantages

| Feature | Ground Edge | Optical Flow |
|---------|------------|--------------|
| Requires motion | âŒ No | âœ… Yes |
| Drift during rotation | âŒ No | âœ… Yes |
| Computational cost | Low | High |
| Works stationary | âœ… Yes | âŒ No |

---

## âœ… Features

- **Complete Navigation Stack** â€” Global planning + local obstacle avoidance
- **Monocular Vision Only** â€” Single RGB camera, no depth sensor
- **Ground Edge Detection** â€” Stable, motion-independent obstacle detection
- **RTAB-Map Integration** â€” Visual SLAM with ORB features (for real robot)
- **Nav2 Integration** â€” Full navigation with costmaps and path planning
- **Multiple Environments** â€” Simple maze, large maze, house, custom worlds
- **Map Creation Tools** â€” Scripts to generate mazes and create occupancy grid maps
- **GUI Teleoperation** â€” Graphical keyboard control with adjustable speed
- **Combined Launch** â€” Single command to start perception + navigation
- **RViz Visualization** â€” Real-time costmap and sensor visualization

---

## ğŸ“¦ Installation

### Prerequisites

**Ubuntu 22.04 + ROS2 Humble**

```bash
# Install ROS2 and dependencies
sudo apt update
sudo apt install -y \
  ros-humble-desktop \
  ros-humble-gazebo-ros-pkgs \
  ros-humble-rtabmap-ros \
  ros-humble-rtabmap-slam \
  ros-humble-robot-state-publisher \
  ros-humble-xacro \
  ros-humble-nav2-bringup \
  ros-humble-navigation2 \
  ros-humble-tf2-tools
```

### Clone & Build

```bash
# Clone repository
git clone https://github.com/yourusername/monocular-depth-navigation.git ~/monocular-depth-navigation

# Build workspace
cd ~/monocular-depth-navigation/ros2_ws
source /opt/ros/humble/setup.bash
colcon build
source install/setup.bash
```

---

## ğŸš€ Quick Start

See **[USAGE.md](USAGE.md)** for detailed step-by-step instructions.

```bash
# Terminal 1: Gazebo simulation
ros2 launch my_robot simple_maze.launch.py

# Terminal 2: Perception + Navigation (combined)
ros2 launch my_robot depth_nav.launch.py

# Terminal 3: RViz visualization
ros2 launch my_robot rviz.launch.py

# Terminal 4: GUI Teleoperation (optional)
ros2 run my_robot teleop_gui.py
```
---

## ğŸ” Key Files (Where Things Live)

- Combined launch (perception + Nav2): [ros2_ws/src/my_robot/launch/depth_nav.launch.py](ros2_ws/src/my_robot/launch/depth_nav.launch.py)
- Nav2 bringup + servers: [ros2_ws/src/my_robot/launch/nav2_local.launch.py](ros2_ws/src/my_robot/launch/nav2_local.launch.py)
- Nav2 parameters (planner/controller/costmaps/BT): [ros2_ws/src/my_robot/config/nav2_local_params.yaml](ros2_ws/src/my_robot/config/nav2_local_params.yaml)
- Ground-edge perception node (C++): [ros2_ws/src/mono_depth_perception/src/ground_edge_node.cpp](ros2_ws/src/mono_depth_perception/src/ground_edge_node.cpp)
- Ground-edge launch + params: [ros2_ws/src/mono_depth_perception/launch/ground_edge.launch.py](ros2_ws/src/mono_depth_perception/launch/ground_edge.launch.py), [ros2_ws/src/mono_depth_perception/config/ground_edge_params.yaml](ros2_ws/src/mono_depth_perception/config/ground_edge_params.yaml)
- RViz launch: [ros2_ws/src/my_robot/launch/rviz.launch.py](ros2_ws/src/my_robot/launch/rviz.launch.py)
- GUI teleop: [ros2_ws/src/my_robot/src/teleop_gui.py](ros2_ws/src/my_robot/src/teleop_gui.py)
- Static map publisher + map tools: [ros2_ws/src/my_robot/scripts/static_map_publisher.py](ros2_ws/src/my_robot/scripts/static_map_publisher.py), [ros2_ws/src/my_robot/scripts/create_map.py](ros2_ws/src/my_robot/scripts/create_map.py), [ros2_ws/src/my_robot/scripts/create_simple_maze_map.py](ros2_ws/src/my_robot/scripts/create_simple_maze_map.py)
- TF tree (generated): [ros2_ws/frames_2026-01-01_15.33.37.pdf](ros2_ws/frames_2026-01-01_15.33.37.pdf)
- Node graph (nodes-only): [ros2_ws/nodes_graph.png](ros2_ws/nodes_graph.png)

---

## ğŸŒ Available Worlds

| World | Launch Command | Description |
|-------|---------------|-------------|
| Simple Maze | `ros2 launch my_robot simple_maze.launch.py` | 25Ã—25m maze, good for testing |
| Large Maze | `ros2 launch my_robot my_maze.launch.py` | 30Ã—30m maze, more complex |
| TurtleBot3 House | `ros2 launch my_robot house.launch.py` | Indoor house with furniture |
| Colorful Obstacles | `ros2 launch my_robot colorful_obstacles.launch.py` | Open area with cylinders |

---

## ğŸ—ºï¸ Map Creation

The project includes tools to generate maze worlds and create occupancy grid maps:

### Generate a New Maze World

```bash
cd ~/monocular-depth-navigation/ros2_ws/src/my_robot/scripts

# Generate simple maze (25x25m)
python3 generate_simple_maze.py

# Generate large maze (30x30m)  
python3 generate_maze.py

# Generate colorful obstacle world
python3 generate_colorful_world.py
```

### Create Occupancy Grid Map from World

After generating a world, create the corresponding map for Nav2:

```bash
# For simple maze
python3 create_simple_maze_map.py

# For large maze
python3 create_map.py
```

Maps are saved to `my_robot/maps/` as PNG/PGM files.

---

## ğŸ¤– Robot Specifications

| Component | Specification |
|-----------|--------------|
| Chassis | Two-plank design (0.25Ã—0.17m) |
| Wheels | 4 wheels, 70mm diameter |
| Drive | Differential (front wheels active) |
| Camera | Monocular, 640Ã—480 @ 30Hz, FOV 1.05 rad |
| IMU | 100Hz, orientation + angular velocity |
| Camera Height | 0.3m above ground |

---

## ğŸ“ Project Structure

```
monocular-depth-navigation/
â”œâ”€â”€ README.md                      # This file
â”œâ”€â”€ USAGE.md                       # Detailed usage instructions
â”œâ”€â”€ LICENSE                        # MIT License
â””â”€â”€ ros2_ws/
    â””â”€â”€ src/
        â”œâ”€â”€ mono_depth_perception/ # Ground edge detection package
        â”‚   â”œâ”€â”€ src/
        â”‚   â”‚   â””â”€â”€ ground_edge_node.cpp
        â”‚   â”œâ”€â”€ config/
        â”‚   â”‚   â””â”€â”€ ground_edge_params.yaml
        â”‚   â””â”€â”€ launch/
        â”‚       â””â”€â”€ ground_edge.launch.py
        â”‚
        â””â”€â”€ my_robot/              # Robot description & launch
            â”œâ”€â”€ urdf/              # Robot URDF/Xacro
            â”œâ”€â”€ worlds/            # Gazebo worlds
            â”‚   â”œâ”€â”€ simple_maze.world
            â”‚   â”œâ”€â”€ my_maze.world
            â”‚   â”œâ”€â”€ house.world
            â”‚   â””â”€â”€ colorful_obstacles.world
            â”œâ”€â”€ maps/              # Occupancy grid maps
            â”œâ”€â”€ scripts/           # Map generation tools
            â”‚   â”œâ”€â”€ generate_maze.py
            â”‚   â”œâ”€â”€ generate_simple_maze.py
            â”‚   â””â”€â”€ create_map.py
            â”œâ”€â”€ launch/
            â”‚   â”œâ”€â”€ depth_nav.launch.py    # Combined perception + nav
            â”‚   â”œâ”€â”€ simple_maze.launch.py
            â”‚   â”œâ”€â”€ my_maze.launch.py
            â”‚   â”œâ”€â”€ nav2_local.launch.py
            â”‚   â”œâ”€â”€ rtabmap.launch.py      # For real robot
            â”‚   â””â”€â”€ rviz.launch.py
            â”œâ”€â”€ config/            # Nav2 params, RViz config
            â””â”€â”€ src/
                â”œâ”€â”€ teleop_gui.py  # GUI teleoperation (recommended)
                â””â”€â”€ teleop.py      # Terminal teleoperation
```

---

## ğŸš€ Launch Files

| Launch File | Purpose |
|-------------|---------|
| `depth_nav.launch.py` | **Recommended** â€” Starts ground edge + Nav2 together |
| `simple_maze.launch.py` | Gazebo with a simple maze |
| `nav2_local.launch.py` | Nav2 navigation stack only |
| `rtabmap.launch.py` | RTAB-Map SLAM (**required for real robot**) |
| `rviz.launch.py` | RViz visualization |
| `ground_edge.launch.py` | Ground edge detection only |

---

## ğŸ“¡ ROS2 Topics

### Perception
| Topic | Type | Description |
|-------|------|-------------|
| `/camera_sensor/image_raw` | Image | RGB camera feed |
| `/camera_sensor/camera_info` | CameraInfo | Camera calibration |
| `/ground_edge_scan` | LaserScan | Obstacle distances from ground edge |
| `/ground_edge_depth` | Float32MultiArray | Per-column depth values |

### Navigation
| Topic | Type | Description |
|-------|------|-------------|
| `/odom` | Odometry | Robot odometry (sim: Gazebo, real: RTAB-Map) |
| `/cmd_vel` | Twist | Velocity commands to robot |
| `/local_costmap/costmap` | OccupancyGrid | Local obstacle map |

---

## âš™ï¸ Configuration

### Ground Edge Parameters

`mono_depth_perception/config/ground_edge_params.yaml`:

```yaml
ground_edge_node:
  ros__parameters:
    camera_topic: "/camera_sensor/image_raw"
    camera_info_topic: "/camera_sensor/camera_info"
    ground_edge:
      roi_ratio: 0.42        # Bottom 42% of image
      min_edge_strength: 50  # Intensity change threshold
      camera_height: 0.3     # Camera height (meters)
      depth_scale: 0.60      # Depth calibration factor
```

### Nav2 Parameters

Key settings in `my_robot/config/nav2_local_params.yaml`:
- Local controller: `RegulatedPurePursuitController` (FollowPath)
- Global planner: `SmacPlannerHybrid` (Hybrid-A*)
- Local + global costmaps: obstacle + inflation layers (obstacle source: `/ground_edge_scan`)
- BT Navigator: behavior-tree-driven navigation + recovery behaviors

---

## ğŸ”® Future Enhancements

This project is **complete and functional**. Potential future additions:

- [ ] **Depth AI Models** â€” MiDaS, DPT, or Depth Anything for learned monocular depth
- [ ] **YOLO Object Detection** â€” Identify and classify specific obstacles
- [ ] **Dynamic Obstacles** â€” Detect and avoid moving objects
- [ ] **Real Hardware Deployment** â€” Raspberry Pi + camera on physical robot

---

## ğŸ› ï¸ Troubleshooting

### Gazebo won't start
```bash
pkill -9 gzserver gzclient
ros2 launch my_robot simple_maze.launch.py
```

### No obstacles in costmap
- Check `/ground_edge_scan` is publishing: `ros2 topic echo /ground_edge_scan`
- Verify camera sees ground-wall transitions
- Adjust `min_edge_strength` for different lighting

### Do obstacles stay during a run?
- During a run, Nav2 maintains a **live obstacle grid** (costmap).
- In this project, the **global costmap keeps obstacles** while Nav2 is running (so they usually donâ€™t disappear).
- The **local costmap updates faster** and can clear obstacles as the sensor updates.
- Nothing is saved to disk (doesn't create a map): restarting Nav2 resets the costmaps.

### Robot doesn't move to goal
- Ensure all nodes are running (simulation, perception, Nav2)
- Check TF tree: `ros2 run tf2_tools view_frames`
- Verify `/odom` is publishing

### Ground edge not detecting obstacles
- Obstacles must touch the ground (floating objects won't be detected)
- Need sufficient contrast between ground and obstacles
- Camera must see the ground-obstacle boundary

### For real robot: No odometry
- **RTAB-Map is required** for real robot â€” it provides visual odometry
- Launch with: `ros2 launch my_robot rtabmap.launch.py`

---

## ğŸ™ Credits

- [ROS2 Humble](https://docs.ros.org/en/humble/) â€” Robot Operating System
- [Nav2](https://navigation.ros.org/) â€” Navigation stack
- [RTAB-Map](https://github.com/introlab/rtabmap_ros) â€” Visual SLAM
- [TurtleBot3](https://github.com/ROBOTIS-GIT/turtlebot3_simulations) â€” Gazebo models

---

## ğŸ“„ License

MIT License â€” See [LICENSE](LICENSE) file for details.

---

## âœ‰ï¸ Contact

For questions or support, please open an issue or contact [Yassineg07](mailto:gharbiyasine040@gmail.com).
