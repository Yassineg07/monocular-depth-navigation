# Monocular Depth Navigation

[![ROS2](https://img.shields.io/badge/ROS2-Humble-blue)](https://docs.ros.org/en/humble/)
[![Gazebo](https://img.shields.io/badge/Gazebo-Classic-orange)](http://gazebosim.org/)

[![Demo Video](https://img.youtube.com/vi/ioWUWzyHvF8/maxresdefault.jpg)](https://youtu.be/ioWUWzyHvF8)

**Autonomous robot navigation using only a monocular RGB camera** â€” no LiDAR, no depth sensor, no AI and no map.

This project demonstrates that a robot can navigate complex environments using computer vision techniques applied to a single camera feed. The robot detects obstacles by analyzing ground-to-wall transitions in the camera image and uses Nav2 for path planning and obstacle avoidance.

---

## ğŸ¯ Project Goal

Build a fully autonomous navigation system that relies solely on:
- **1 RGB camera** (640Ã—480 @ 30Hz)
- **Visual odometry** (RTAB-Map with ORB features â€” required for real robot, optional in simulation)
- **Ground edge detection** (custom perception algorithm)
- **Nav2** (global + local planning)

No expensive sensors required!

---

## ğŸ”¬ How Ground Edge Detection Works

Traditional monocular depth estimation requires robot motion (optical flow triangulation) and suffers from drift during rotation. This project uses a simpler, more robust approach:

### The Algorithm

1. **Focus on ground region** â€” Analyze bottom 42% of camera image
2. **Scan each column** â€” From bottom to top, detect intensity changes
3. **Find obstacle edge** â€” Where ground meets wall/obstacle
4. **Calculate depth** â€” Using camera geometry:
   ```
   depth = camera_height / tan(pixel_angle)
   ```
5. **Publish LaserScan** â€” Convert to `/ground_edge_scan` for Nav2

### Advantages

| Feature | Ground Edge | Optical Flow |
|---------|------------|--------------|
| Requires motion | âŒ No | âœ… Yes |
| Drift during rotation | âŒ No | âœ… Yes |
| Computational cost | Low | High |
| Works stationary | âœ… Yes | âŒ No |

---

### Do obstacles â€œstayâ€ while running?

- At startup, the robot is basically **blind**: obstacle grids start empty.
- While Nav2 is running, obstacles are added to a **live obstacle grid** (costmap) as the robot detects them.
- In this project, the **global costmap tends to keep obstacles** during the run, while the **local costmap can clear them** as the sensor updates.
- Nothing is saved to disk: restarting Nav2 resets the costmaps.

### About the reference â€œmapâ€ in RViz (occupancy grid)

This repo can generate an occupancy grid image for **RViz/visual reference and easier goal placement only**.

- Nav2 navigation here is driven by the live costmaps built from `/ground_edge_scan`.
- The occupancy grid image is **not** used by Nav2 for planning/navigation in this project.

---

## ğŸ—ï¸ System Architecture

At a glance:
- Camera â†’ ground-edge detection â†’ `/ground_edge_scan` â†’ Nav2 costmaps â†’ planner/controller â†’ `/cmd_vel`
- Nav2 plugins used: `RegulatedPurePursuitController` (local controller) + `SmacPlannerHybrid` (global planner)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         GAZEBO SIMULATION                           â”‚
â”‚   Robot with Camera (640Ã—480) + IMU + Differential Drive            â”‚
â”‚   (Provides ground-truth odometry via diff_drive plugin)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼                   â–¼                   â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  RTAB-Map SLAM  â”‚  â”‚ Ground Edge Nodeâ”‚  â”‚ Map Creation Tools  â”‚
   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
   â”‚ â€¢ ORB features  â”‚  â”‚ â€¢ Edge detectionâ”‚  â”‚ â€¢ generate_maze.py  â”‚
   â”‚ â€¢ Visual odom   â”‚  â”‚ â€¢ Depth from    â”‚  â”‚ â€¢ create_map.py     â”‚
   â”‚ â€¢ Loop closure  â”‚  â”‚   geometry      â”‚  â”‚ â†’ Occupancy grid    â”‚
   â”‚ â†’ /odom, /tf    â”‚  â”‚ â†’ /ground_edge_ â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚                 â”‚  â”‚   scan          â”‚
   â”‚ (Real robot     â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚  only - not     â”‚            â”‚
   â”‚  needed in sim) â”‚            â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
              â”‚                   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚         NAV2            â”‚
          â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
          â”‚  â€¢ Global planner       â”‚
          â”‚  â€¢ Local costmap        â”‚
          â”‚  â€¢ Regulated Pure       â”‚
          â”‚     Pursuit controller  â”‚
          â”‚  â†’ /cmd_vel             â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
                 Robot Motion
```

### Simulation vs Real Robot

| Component | Gazebo Simulation | Real Robot |
|-----------|-------------------|------------|
| Odometry | Gazebo diff_drive plugin (ground truth) | **RTAB-Map required** |
| RTAB-Map | Optional (can use for mapping) | **Required for visual odometry** |
| Perception | Ground Edge Detection | Ground Edge Detection |
| Navigation | Nav2 | Nav2 |

---

## âœ… Features

- **Complete Navigation Stack** â€” Global planning + local obstacle avoidance
- **Monocular Vision Only** â€” Single RGB camera, no depth sensor
- **Ground Edge Detection** â€” Stable, motion-independent obstacle detection
- **RTAB-Map Integration** â€” Visual SLAM with ORB features (for real robot)
- **Nav2 Integration** â€” Full navigation with costmaps and path planning
- **Multiple Environments** â€” Simple maze, large maze, house, custom worlds
- **Map Creation Tools** â€” Scripts to generate mazes and create occupancy grid maps
- **GUI Teleoperation** â€” Graphical keyboard control with adjustable speed
- **Combined Launch** â€” Single command to start perception + navigation
- **RViz Visualization** â€” Real-time costmap and sensor visualization

---

## ğŸ“¦ Setup

Detailed setup and run instructions are in [USAGE.md](USAGE.md).

### Clone & Build

```bash
# Clone repository
git clone https://github.com/Yassineg07/monocular-depth-navigation.git ~/monocular-depth-navigation

# Build workspace
cd ~/monocular-depth-navigation/ros2_ws
source /opt/ros/humble/setup.bash
colcon build
source install/setup.bash
```

---

## ğŸ“ Project Structure

```
monocular-depth-navigation/
â”œâ”€â”€ README.md
â”œâ”€â”€ USAGE.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ .gitignore
â””â”€â”€ ros2_ws/
    â”œâ”€â”€ cleanup_ros.sh
    â”œâ”€â”€ nodes_graph.png            # Node graph artifact
    â”œâ”€â”€ frames_2026-01-01_15.33.37.pdf  # TF tree artifact
    â”œâ”€â”€ frames_2026-01-01_15.33.37.gv
    â””â”€â”€ src/
        â”œâ”€â”€ mono_depth_perception/      # Ground edge detection package
        â”‚   â”œâ”€â”€ launch/ground_edge.launch.py
        â”‚   â”œâ”€â”€ config/ground_edge_params.yaml
        â”‚   â”œâ”€â”€ src/ground_edge_node.cpp
        â”‚   â””â”€â”€ include/
        â””â”€â”€ my_robot/                   # Robot description + launch + Nav2 config
            â”œâ”€â”€ launch/                 # Gazebo + Nav2 + RViz entrypoints
            â”œâ”€â”€ config/                 # Nav2 params (costmaps/planner/controller)
            â”‚   â””â”€â”€ nav2_local_params.yaml
            â”œâ”€â”€ scripts/                # Map tools + static_map_publisher
            â”œâ”€â”€ src/                    # Teleop + utilities
            â”œâ”€â”€ urdf/
            â”œâ”€â”€ worlds/
            â”œâ”€â”€ maps/
            â”œâ”€â”€ meshes/
            â”œâ”€â”€ models/
            â””â”€â”€ include/
```

---

## ğŸ”® Future Enhancements

This project is **complete and functional**. Potential future additions:

- [ ] **Depth AI Models** â€” MiDaS, DPT, or Depth Anything for learned monocular depth
- [ ] **YOLO Object Detection** â€” Identify and classify specific obstacles
- [ ] **Dynamic Obstacles** â€” Detect and avoid moving objects
- [ ] **Real Hardware Deployment** â€” Raspberry Pi + camera on physical robot

---

## ğŸ™ Credits

- [ROS2 Humble](https://docs.ros.org/en/humble/) â€” Robot Operating System
- [Nav2](https://navigation.ros.org/) â€” Navigation stack
- [RTAB-Map](https://github.com/introlab/rtabmap_ros) â€” Visual SLAM
- [TurtleBot3](https://github.com/ROBOTIS-GIT/turtlebot3_simulations) â€” Gazebo models

---

## ğŸ“„ License

MIT License â€” See [LICENSE](LICENSE) file for details.

---

## âœ‰ï¸ Contact

For questions or support, please open an issue or contact [Yassineg07](mailto:gharbiyasine040@gmail.com).
